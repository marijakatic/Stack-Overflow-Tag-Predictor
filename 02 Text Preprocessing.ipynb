{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "02 Text Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51790397"
      },
      "source": [
        "# <center> Text preprocessing </center>"
      ],
      "id": "51790397"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbyCupCjB3AF"
      },
      "source": [
        "## Necessary downloads and library imports"
      ],
      "id": "MbyCupCjB3AF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRWujV7YCYU2",
        "outputId": "a5fe974b-1673-4871-982c-e4d9d270e506"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "WRWujV7YCYU2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syaBWbsVvpXm"
      },
      "source": [
        "project_path = '/content/drive/My Drive/Colab Notebooks/MATF_ML_project/'"
      ],
      "id": "syaBWbsVvpXm",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0a49eb9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "import regex as re\n",
        "import string"
      ],
      "id": "f0a49eb9",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zWhTEx3DBWe",
        "outputId": "498d373f-0565-4185-ae3c-cda350a6988c"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "!pip install lxml"
      ],
      "id": "2zWhTEx3DBWe",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b2eb199"
      },
      "source": [
        "## Load data"
      ],
      "id": "1b2eb199"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d3ba881"
      },
      "source": [
        "We will turn off the detection of missing value markers due to the presence of \"null\" tags that are otherwise recognised as NA values. There are no true NA values in the data.\n",
        "\n",
        "In order to avoid computation constraints with training and evaluation we will use a small subset of the data. Only 10,000 instances."
      ],
      "id": "4d3ba881"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "300660aa"
      },
      "source": [
        "data = pd.read_csv(project_path + 'data/Train.csv',\n",
        "                   na_filter=False, nrows=10000)"
      ],
      "id": "300660aa",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8038319"
      },
      "source": [
        "## Duplicates in data"
      ],
      "id": "b8038319"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b69b3bbb"
      },
      "source": [
        "data_without_duplicates = data.drop_duplicates(['Title', 'Body', 'Tags'])"
      ],
      "id": "b69b3bbb",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d3e80da",
        "outputId": "fd83f951-b74f-4c55-a8f6-fcef47c58e0d"
      },
      "source": [
        "print(\"Shape with duplicates\\t\", data.shape)\n",
        "print(\"Shape without duplicates\", data_without_duplicates.shape)"
      ],
      "id": "1d3e80da",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape with duplicates\t (10000, 4)\n",
            "Shape without duplicates (9997, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ed8b854"
      },
      "source": [
        "data = data_without_duplicates"
      ],
      "id": "0ed8b854",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLoNrvQrYVY6"
      },
      "source": [
        "### Drop rare tags"
      ],
      "id": "qLoNrvQrYVY6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoTGGo3Z-CbR"
      },
      "source": [
        "In order to avoid computation constraints with training and evaluation of the data, we will limit our tag prediction to the top 100 most frequent tags."
      ],
      "id": "ZoTGGo3Z-CbR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFDDIcaB_hcX"
      },
      "source": [
        "N_tags = 100"
      ],
      "id": "XFDDIcaB_hcX",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TFsDavAYTHd",
        "outputId": "da4e85cc-bbe3-41e1-fe80-74888adb2f0a"
      },
      "source": [
        "tags_per_question = list(map(lambda tags: tags.split(' '), data[\"Tags\"]))\n",
        "all_tags = [item for sublist in tags_per_question for item in sublist]\n",
        "all_tags = np.array(all_tags)\n",
        "print(len(np.unique(all_tags)))\n",
        "print(\"Tags:\", all_tags)"
      ],
      "id": "8TFsDavAYTHd",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6124\n",
            "Tags: ['php' 'image-processing' 'file-upload' ... 'haskell' '.net'\n",
            " 'entity-framework-4']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q267u82WYTLU"
      },
      "source": [
        "unique, counts = np.unique(all_tags, return_counts=True)\n",
        "tag_counts = dict(zip(unique, counts))"
      ],
      "id": "Q267u82WYTLU",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8JNFyvwYTP0",
        "outputId": "76a721b3-6b3a-4572-89d2-96d5bb43e22c"
      },
      "source": [
        "list(tag_counts.items())[:10]"
      ],
      "id": "E8JNFyvwYTP0",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.htaccess', 40),\n",
              " ('.net', 302),\n",
              " ('.net-2.0', 6),\n",
              " ('.net-3.5', 7),\n",
              " ('.net-4.0', 10),\n",
              " ('.net-4.5', 3),\n",
              " ('.net-assembly', 3),\n",
              " ('.net-framework', 1),\n",
              " ('.net4.0', 1),\n",
              " ('.refresh', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rfZo8tEiOGO"
      },
      "source": [
        "tag_counts_sorted = dict(sorted(tag_counts.items(), key=lambda item: item[1], reverse=True))"
      ],
      "id": "9rfZo8tEiOGO",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35VrcjhMZNQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b605d21-b838-43f4-d353-d1d49c2fd655"
      },
      "source": [
        "print('Total number of tags is', len(tag_counts_sorted))"
      ],
      "id": "35VrcjhMZNQ5",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of tags is 6124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIBxVL7JZNaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da51706a-e62d-4052-8d0e-adf6d5aedc14"
      },
      "source": [
        "print(\"Most frequent tags:\")\n",
        "print(list(tag_counts_sorted.keys())[:20])"
      ],
      "id": "XIBxVL7JZNaY",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most frequent tags:\n",
            "['c#', 'java', 'php', 'javascript', 'android', 'jquery', 'c++', 'asp.net', '.net', 'iphone', 'python', 'html', 'mysql', 'sql', 'ios', 'css', 'linux', 'ruby-on-rails', 'objective-c', 'c']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9U0owdKZNd9",
        "outputId": "540e5c41-0fec-43b5-ad00-aa8c32f80121"
      },
      "source": [
        "print(\"Rarest tags:\")\n",
        "print(list(tag_counts_sorted.keys())[-20:])"
      ],
      "id": "g9U0owdKZNd9",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rarest tags:\n",
            "['z-order', 'z3', 'zebra-printers', 'zedgraph', 'zenbook', 'zend-amf', 'zend-auth', 'zend-controller-router', 'zend-debugger', 'zend-form', 'zend-log', 'zend-paginator', 'zend-route', 'zend-search-lucene', 'zend-server', 'zend-server-ce', 'zepto', 'zigbee', 'zooming', 'zxing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBNis5WXZNil"
      },
      "source": [
        "tags_most_frequent = list(tag_counts_sorted.keys())[:N_tags]"
      ],
      "id": "CBNis5WXZNil",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xoiWDJ2eMNk",
        "outputId": "c218350c-1a34-4e37-b62f-14873511952c"
      },
      "source": [
        "print(\"Top\", N_tags, \"tags:\")\n",
        "print(tags_most_frequent)"
      ],
      "id": "7xoiWDJ2eMNk",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 100 tags:\n",
            "['c#', 'java', 'php', 'javascript', 'android', 'jquery', 'c++', 'asp.net', '.net', 'iphone', 'python', 'html', 'mysql', 'sql', 'ios', 'css', 'linux', 'ruby-on-rails', 'objective-c', 'c', 'windows', 'ruby', 'sql-server', 'xml', 'wpf', 'database', 'ajax', 'asp.net-mvc', 'arrays', 'regex', 'xcode', 'facebook', 'osx', 'windows-7', 'performance', 'multithreading', 'networking', 'vb.net', 'ruby-on-rails-3', 'eclipse', 'actionscript-3', 'linq', 'html5', 'django', 'algorithm', 'json', 'flash', 'visual-studio-2010', 'string', 'wcf', 'oracle', 'bash', 'entity-framework', 'winforms', 'sql-server-2008', 'asp.net-mvc-3', 'ubuntu', 'silverlight', 'ipad', 'email', 'query', 'hibernate', 'image', 'web-services', 'wordpress', 'cocoa-touch', 'r', 'git', 'spring', 'apache', 'cocoa', 'visual-studio', 'homework', 'flex', 'apache2', 'calculus', 'excel', 'real-analysis', '.htaccess', 'codeigniter', 'forms', 'events', 'tsql', 'api', 'http', 'security', 'file', 'jquery-ui', 'sql-server-2005', 'perl', 'windows-phone-7', 'tomcat', 'facebook-graph-api', 'jsp', 'magento', 'mvc', 'pdf', 'sqlite', 'centos', 'firefox']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM_rKnzVAn3T"
      },
      "source": [
        "Drop rare tags from questions:"
      ],
      "id": "QM_rKnzVAn3T"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfOoGUYycNTa"
      },
      "source": [
        "new_data_tags = []\n",
        "for tags in data['Tags']:\n",
        "    new_tags = [tag for tag in tags.split(\" \") if tag in tags_most_frequent]\n",
        "    if not new_tags:\n",
        "        new_tags=None\n",
        "    new_data_tags.append(new_tags)"
      ],
      "id": "BfOoGUYycNTa",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg6eBsRJcNpG"
      },
      "source": [
        "data['Tags'] = new_data_tags"
      ],
      "id": "wg6eBsRJcNpG",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hv7EpxF0cN1V",
        "outputId": "732c9089-dfab-4683-ac68-eaa7be3cd922"
      },
      "source": [
        "data.head()"
      ],
      "id": "hv7EpxF0cN1V",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>How to check if an uploaded file is an image w...</td>\n",
              "      <td>&lt;p&gt;I'd like to check if an uploaded file is an...</td>\n",
              "      <td>[php]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>How can I prevent firefox from closing when I ...</td>\n",
              "      <td>&lt;p&gt;In my favorite editor (vim), I regularly us...</td>\n",
              "      <td>[firefox]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>R Error Invalid type (list) for variable</td>\n",
              "      <td>&lt;p&gt;I am import matlab file and construct a dat...</td>\n",
              "      <td>[r]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>How do I replace special characters in a URL?</td>\n",
              "      <td>&lt;p&gt;This is probably very simple, but I simply ...</td>\n",
              "      <td>[c#]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How to modify whois contact details?</td>\n",
              "      <td>&lt;pre&gt;&lt;code&gt;function modify(.......)\\n{\\n  $mco...</td>\n",
              "      <td>[php, api]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...        Tags\n",
              "0   1  ...       [php]\n",
              "1   2  ...   [firefox]\n",
              "2   3  ...         [r]\n",
              "3   4  ...        [c#]\n",
              "4   5  ...  [php, api]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqYDcEhCcN5x",
        "outputId": "4278904d-efc1-4c04-dbc2-03062c91d34b"
      },
      "source": [
        "data.shape"
      ],
      "id": "iqYDcEhCcN5x",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9997, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS0cejSpshhL"
      },
      "source": [
        "Drop instances that left without tags:"
      ],
      "id": "tS0cejSpshhL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHcl7Sr1fYs0"
      },
      "source": [
        "data = data.dropna()"
      ],
      "id": "AHcl7Sr1fYs0",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YWWSNkOfY0x",
        "outputId": "b3247c6c-82f5-4a9e-e840-0bc44464a127"
      },
      "source": [
        "data.shape"
      ],
      "id": "6YWWSNkOfY0x",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7628, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e01f03f"
      },
      "source": [
        "## Text preprocessing"
      ],
      "id": "7e01f03f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aac26d3b"
      },
      "source": [
        "test_str = \"<body><p>There're some files: index.html, my.file.txt, file.c, file.ext-with-dash and I hope toktok-tokenizer will properly tokenize it.\\n New line. This is new sentence. The most common tag is C#.... ++++++++++++++++++  ======================== R and C++ and C++11 and C aren't so frequent.<br> Some words with numbers: word1, word32, word-2.</p></body> There are some functions: main(), str(), f().<br>There are some urls: https://www.google.com https://www.google.com/dir/1/2/search.html?arg=0-a&arg1=1-b&arg3-c#hash https://google.us.edi?34535/534534?dfg=g&fg. Some numbers:  0123, 2021, 30912, 0000\""
      ],
      "id": "aac26d3b",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4bc615c"
      },
      "source": [
        "#### Removing HTML tags"
      ],
      "id": "d4bc615c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dd1647f"
      },
      "source": [
        "We choose `lxml` believing it to be faster and more robust than the default one (```html.parser```)."
      ],
      "id": "6dd1647f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef81b15b"
      },
      "source": [
        "def remove_html(s):\n",
        "    return BeautifulSoup(s, 'lxml').get_text()"
      ],
      "id": "ef81b15b",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "b064c23b",
        "outputId": "98b3ebe1-9555-421a-e727-4d2ab770b7f0"
      },
      "source": [
        "test_str = remove_html(test_str)\n",
        "test_str"
      ],
      "id": "b064c23b",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There're some files: index.html, my.file.txt, file.c, file.ext-with-dash and I hope toktok-tokenizer will properly tokenize it.\\n New line. This is new sentence. The most common tag is C#.... ++++++++++++++++++  ======================== R and C++ and C++11 and C aren't so frequent. Some words with numbers: word1, word32, word-2. There are some functions: main(), str(), f().There are some urls: https://www.google.com https://www.google.com/dir/1/2/search.html?arg=0-a&arg1=1-b&arg3-c#hash https://google.us.edi?34535/534534?dfg=g&fg. Some numbers:  0123, 2021, 30912, 0000\""
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5de112e"
      },
      "source": [
        "#### Cleaning text"
      ],
      "id": "d5de112e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDeJT_2sB5S8"
      },
      "source": [
        "Lowering text and transforming abbreviations."
      ],
      "id": "HDeJT_2sB5S8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opWGFc0wNuOQ"
      },
      "source": [
        "file = open(project_path + \"data/abbr.pkl\", \"rb\")\n",
        "abbr_dict = pickle.load(file)\n",
        "file.close()"
      ],
      "id": "opWGFc0wNuOQ",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foU5p-Pusv3L",
        "outputId": "b18323d1-d59e-456e-b3b6-424fb860ea60"
      },
      "source": [
        "list(abbr_dict.items())[:10]"
      ],
      "id": "foU5p-Pusv3L",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"what's\", 'what is'),\n",
              " (\"what're\", 'what are'),\n",
              " (\"who's\", 'who is'),\n",
              " (\"who're\", 'who are'),\n",
              " (\"where's\", 'where is'),\n",
              " (\"where're\", 'where are'),\n",
              " (\"when's\", 'when is'),\n",
              " (\"when're\", 'when are'),\n",
              " (\"how's\", 'how is'),\n",
              " (\"how're\", 'how are')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42134fa6"
      },
      "source": [
        "def clean_text(s, abbr_dict=None):\n",
        "    s = s.lower()\n",
        "    \n",
        "    if abbr_dict is None:\n",
        "      return s\n",
        "\n",
        "    for patt, repl in abbr_dict.items():\n",
        "        s = re.sub(patt, repl, s)\n",
        "    return s"
      ],
      "id": "42134fa6",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "8557eec3",
        "outputId": "0e9cdff1-0964-4f90-cd19-41b264c6c8ae"
      },
      "source": [
        "test_str = clean_text(test_str, abbr_dict)\n",
        "test_str"
      ],
      "id": "8557eec3",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'there are some files: index.html, my.file.txt, file.c, file.ext-with-dash and i hope toktok-tokenizer will properly tokenize it.\\n new line. this is new sentence. the most common tag is c#.... ++++++++++++++++++  ======================== r and c++ and c++11 and c are not so frequent. some words with numbers: word1, word32, word-2. there are some functions: main(), str(), f().there are some urls: https://www.google.com https://www.google.com/dir/1/2/search.html?arg=0-a&arg1=1-b&arg3-c#hash https://google.us.edi?34535/534534?dfg=g&fg. some numbers:  0123, 2021, 30912, 0000'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68ec8ee4"
      },
      "source": [
        "#### Tokenization"
      ],
      "id": "68ec8ee4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e20049d4"
      },
      "source": [
        "We examined the following tokenizers on our data:\n",
        "* ```nltk.tokenize.word_tokenize()```\n",
        "* ```nltk.tokenize.WhitespaceTokenizer()```\n",
        "* ```nltk.tokenize.ToktokTokenizer()```\n",
        "* ```nltk.tokenize.TweetTokenizer()```\n",
        "* ```nltk.tokenize.treebank.TreebankWordTokenizer()```\n",
        "\n",
        "and TokTokTokenizer seemed most applicable."
      ],
      "id": "e20049d4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf101qusOl0I"
      },
      "source": [
        "word_tokenizer = nltk.tokenize.ToktokTokenizer()"
      ],
      "id": "wf101qusOl0I",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7a85e6e"
      },
      "source": [
        "def tokenize_text(s, word_tokenizer):\n",
        "    sentences = nltk.tokenize.sent_tokenize(s)\n",
        "    # suming lists, tokenize_sents returns list(list(str))\n",
        "    return sum(word_tokenizer.tokenize_sents(sentences), [])"
      ],
      "id": "a7a85e6e",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d14e9805",
        "outputId": "13413749-f263-449a-b5f7-14b00dbbb46a"
      },
      "source": [
        "test_tokens = tokenize_text(test_str, word_tokenizer)\n",
        "print(test_tokens)"
      ],
      "id": "d14e9805",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['there', 'are', 'some', 'files', ':', 'index.html', ',', 'my.file.txt', ',', 'file.c', ',', 'file.ext-with-dash', 'and', 'i', 'hope', 'toktok-tokenizer', 'will', 'properly', 'tokenize', 'it', '.', 'new', 'line', '.', 'this', 'is', 'new', 'sentence', '.', 'the', 'most', 'common', 'tag', 'is', 'c#', '....', '++++++++++++++++++', '========================', 'r', 'and', 'c++', 'and', 'c++11', 'and', 'c', 'are', 'not', 'so', 'frequent', '.', 'some', 'words', 'with', 'numbers', ':', 'word1', ',', 'word32', ',', 'word-2', '.', 'there', 'are', 'some', 'functions', ':', 'main(', ')', ',', 'str(', ')', ',', 'f(', ')', '.there', 'are', 'some', 'urls', ':', 'https://www.google.com', 'https://www.google.com/dir/1/2/search.html?arg=0-a&arg1=1-b&arg3-c#hash', 'https://google.us.edi?34535/534534?dfg=g&fg', '.', 'some', 'numbers', ':', '0123', ',', '2021', ',', '30912', ',', '0000']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ba514f"
      },
      "source": [
        "#### Process URLs"
      ],
      "id": "a5ba514f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiLqcpMqCxqS"
      },
      "source": [
        "We firstly considered extracting the URL into meaningful parts (host, path, query, ...) but it turned out that meaningless parts were dominant in number and that created noise in data.\n",
        "So we decided to remove URLs at all."
      ],
      "id": "AiLqcpMqCxqS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0815d786"
      },
      "source": [
        "def remove_urls(tokens):\n",
        "    new_tokens = []\n",
        "    url_pattern = r\"^((http[s]?|ftp):\\/)?\\/?([^:\\/\\s]*)((\\/\\w+)*\\/)([\\w\\-\\.]+[^#?\\s]+)(.*)?(#[\\w\\-]+)?$\"\n",
        "    for token in tokens:\n",
        "        if not re.match(url_pattern, token):\n",
        "            new_tokens.append(token)\n",
        "    return new_tokens\n",
        "    "
      ],
      "id": "0815d786",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv-fspuetCmH",
        "outputId": "150b17b6-bd9b-4eb3-9c43-3fcfea0227c6"
      },
      "source": [
        "test_tokens = remove_urls(test_tokens)\n",
        "print(test_tokens)"
      ],
      "id": "tv-fspuetCmH",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['there', 'are', 'some', 'files', ':', 'index.html', ',', 'my.file.txt', ',', 'file.c', ',', 'file.ext-with-dash', 'and', 'i', 'hope', 'toktok-tokenizer', 'will', 'properly', 'tokenize', 'it', '.', 'new', 'line', '.', 'this', 'is', 'new', 'sentence', '.', 'the', 'most', 'common', 'tag', 'is', 'c#', '....', '++++++++++++++++++', '========================', 'r', 'and', 'c++', 'and', 'c++11', 'and', 'c', 'are', 'not', 'so', 'frequent', '.', 'some', 'words', 'with', 'numbers', ':', 'word1', ',', 'word32', ',', 'word-2', '.', 'there', 'are', 'some', 'functions', ':', 'main(', ')', ',', 'str(', ')', ',', 'f(', ')', '.there', 'are', 'some', 'urls', ':', '.', 'some', 'numbers', ':', '0123', ',', '2021', ',', '30912', ',', '0000']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ebc5e22"
      },
      "source": [
        "#### Process extensions"
      ],
      "id": "4ebc5e22"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZNoSfO3Ei1C"
      },
      "source": [
        "File extensions are very important features because there are also file extensions as tags!"
      ],
      "id": "iZNoSfO3Ei1C"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab5bc099"
      },
      "source": [
        "def extract_extensions(tokens):\n",
        "    new_tokens = []\n",
        "    for token in tokens:\n",
        "        token = re.sub(r\"([a-zA-Z0-9])\\.([a-zA-Z0-9-])\", r'\\1 .\\2', token)\n",
        "        for new_token in token.split(\" \"):\n",
        "            new_tokens.append(new_token)\n",
        "    return new_tokens"
      ],
      "id": "ab5bc099",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88abc88a",
        "outputId": "53d945e2-34e2-4c35-beeb-8ef06b30ed16"
      },
      "source": [
        "test_tokens = extract_extensions(test_tokens)\n",
        "print(test_tokens)"
      ],
      "id": "88abc88a",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['there', 'are', 'some', 'files', ':', 'index', '.html', ',', 'my', '.file', '.txt', ',', 'file', '.c', ',', 'file', '.ext-with-dash', 'and', 'i', 'hope', 'toktok-tokenizer', 'will', 'properly', 'tokenize', 'it', '.', 'new', 'line', '.', 'this', 'is', 'new', 'sentence', '.', 'the', 'most', 'common', 'tag', 'is', 'c#', '....', '++++++++++++++++++', '========================', 'r', 'and', 'c++', 'and', 'c++11', 'and', 'c', 'are', 'not', 'so', 'frequent', '.', 'some', 'words', 'with', 'numbers', ':', 'word1', ',', 'word32', ',', 'word-2', '.', 'there', 'are', 'some', 'functions', ':', 'main(', ')', ',', 'str(', ')', ',', 'f(', ')', '.there', 'are', 'some', 'urls', ':', '.', 'some', 'numbers', ':', '0123', ',', '2021', ',', '30912', ',', '0000']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "635dc8be"
      },
      "source": [
        "#### Punctuation"
      ],
      "id": "635dc8be"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gngrEkYVG-0w"
      },
      "source": [
        "Removing punctuation but keeping:\n",
        "* tokens like 'c#', 'c++', ...\n",
        "* dots in file extensions (this significantly improved the metrics value!)"
      ],
      "id": "gngrEkYVG-0w"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nOs8Tgn9OlFu",
        "outputId": "834c3e9f-e772-453f-e835-a5493da3852c"
      },
      "source": [
        "string.punctuation"
      ],
      "id": "nOs8Tgn9OlFu",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FELRnCSjJ9uk"
      },
      "source": [
        "punctuation_without_dash = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~'"
      ],
      "id": "FELRnCSjJ9uk",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dGKZPzRHxGy"
      },
      "source": [
        "def extension(word):\n",
        "    if len(word) < 2:\n",
        "        return False\n",
        "    if word[0] != '.':\n",
        "        return False\n",
        "    for letter in word[1:]:\n",
        "        if letter in punctuation_without_dash:\n",
        "            return False\n",
        "    return True"
      ],
      "id": "2dGKZPzRHxGy",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdc86699"
      },
      "source": [
        "def remove_punctuation(tokens):\n",
        "    new_tokens = []\n",
        "    for token in tokens:\n",
        "        if not extension(token):\n",
        "            while len(token) != 0 and token[0] in string.punctuation:\n",
        "                token = token[1:]\n",
        "            while len(token) != 0 and token[-1] == '(':\n",
        "                token = token[:-1]\n",
        "        if len(token) != 0:\n",
        "            new_tokens.append(token)\n",
        "    return new_tokens"
      ],
      "id": "cdc86699",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70a25282",
        "outputId": "80ee4149-3074-41f1-b3b1-ee63c1b1ee59"
      },
      "source": [
        "test_tokens = remove_punctuation(test_tokens)\n",
        "print(test_tokens)"
      ],
      "id": "70a25282",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['there', 'are', 'some', 'files', 'index', '.html', 'my', '.file', '.txt', 'file', '.c', 'file', '.ext-with-dash', 'and', 'i', 'hope', 'toktok-tokenizer', 'will', 'properly', 'tokenize', 'it', 'new', 'line', 'this', 'is', 'new', 'sentence', 'the', 'most', 'common', 'tag', 'is', 'c#', 'r', 'and', 'c++', 'and', 'c++11', 'and', 'c', 'are', 'not', 'so', 'frequent', 'some', 'words', 'with', 'numbers', 'word1', 'word32', 'word-2', 'there', 'are', 'some', 'functions', 'main', 'str', 'f', '.there', 'are', 'some', 'urls', 'some', 'numbers', '0123', '2021', '30912', '0000']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47415c95"
      },
      "source": [
        "#### Stopwords"
      ],
      "id": "47415c95"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jh8sBT0Pwkr"
      },
      "source": [
        "There are tags like 'design' so we think that tokens like 'why', 'how', 'what' are important (e.g. 'how' is maybe important for tag 'design') and we will not remove them. Also, we will not remove single-letter tokens (for example 'o')."
      ],
      "id": "5jh8sBT0Pwkr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d39f02d"
      },
      "source": [
        "stopwords_eng = stopwords.words('english')"
      ],
      "id": "2d39f02d",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6045b6f6",
        "outputId": "6c13dcc8-b75e-4324-e2d3-49ff3ccb3817"
      },
      "source": [
        "print(stopwords_eng)"
      ],
      "id": "6045b6f6",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "636efdb5"
      },
      "source": [
        "not_stopwords = ['what', 'which', 'who', 'about', 'where', 'why', 'how',\n",
        "                  'no', 'not', 'on', 'off', 'o', 're', 'y']"
      ],
      "id": "636efdb5",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea5efa78"
      },
      "source": [
        "my_stopwords = [word for word in stopwords_eng if word not in not_stopwords]\n",
        "# my_stopwords"
      ],
      "id": "ea5efa78",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67e0581c"
      },
      "source": [
        "def remove_stopwords(tokens, stopwords):\n",
        "    return [token for token in tokens if token not in stopwords]"
      ],
      "id": "67e0581c",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYLcBtVHtc1a",
        "outputId": "a4b3bb89-8b36-4981-8fab-d297510a353f"
      },
      "source": [
        "test_tokens = remove_stopwords(test_tokens, my_stopwords)\n",
        "print(test_tokens)"
      ],
      "id": "ZYLcBtVHtc1a",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['files', 'index', '.html', '.file', '.txt', 'file', '.c', 'file', '.ext-with-dash', 'hope', 'toktok-tokenizer', 'properly', 'tokenize', 'new', 'line', 'new', 'sentence', 'common', 'tag', 'c#', 'r', 'c++', 'c++11', 'c', 'not', 'frequent', 'words', 'numbers', 'word1', 'word32', 'word-2', 'functions', 'main', 'str', 'f', '.there', 'urls', 'numbers', '0123', '2021', '30912', '0000']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03f4f288"
      },
      "source": [
        "#### Numbers"
      ],
      "id": "03f4f288"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLIKxGOnRpkx"
      },
      "source": [
        "To reduce the number of useless tokens we will reduce the numbers in text.\n",
        "However, we will not completely eliminate them because they are important for questions from mathematical topics. We will replace number with one digit. \n",
        "\n",
        "In order not to lose the years from the text, which are also important, because they are often found in the names of software versions for example, we will save all the numbers between 1900 and 2100. \n",
        "\n",
        "To make sure of that, later in the notebook we will count occurrences of some years in the text.\n",
        "\n",
        "NOTE: There is a lot of room for improvement in this approach. "
      ],
      "id": "kLIKxGOnRpkx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0d8beb6"
      },
      "source": [
        "def process_numbers(tokens):\n",
        "    new_tokens = []\n",
        "    for token in tokens:\n",
        "        while len(token) != 0 and token[0] == '0':\n",
        "            token = token[1:]\n",
        "\n",
        "        if token.isdigit() and len(token) == 4 and (int(token) > 1900 and int(token) < 2100): # token is PROBABLY a year\n",
        "            new_tokens.append(token)\n",
        "        elif token.isdigit():\n",
        "            new_tokens.append(token[0])\n",
        "        elif len(token) != 0:\n",
        "            new_tokens.append(token)\n",
        "    return new_tokens"
      ],
      "id": "a0d8beb6",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95106223",
        "outputId": "6e06d868-e925-4143-8fe3-b5cda3fef5ad"
      },
      "source": [
        "test_tokens = process_numbers(test_tokens)\n",
        "print(test_tokens)"
      ],
      "id": "95106223",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['files', 'index', '.html', '.file', '.txt', 'file', '.c', 'file', '.ext-with-dash', 'hope', 'toktok-tokenizer', 'properly', 'tokenize', 'new', 'line', 'new', 'sentence', 'common', 'tag', 'c#', 'r', 'c++', 'c++11', 'c', 'not', 'frequent', 'words', 'numbers', 'word1', 'word32', 'word-2', 'functions', 'main', 'str', 'f', '.there', 'urls', 'numbers', '1', '2021', '3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37ecae4b"
      },
      "source": [
        "#### Stemmer"
      ],
      "id": "37ecae4b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc83a267"
      },
      "source": [
        "We examined the following stemmers on our data:\n",
        "* `nltk.stem.PorterStemmer(language='english')` - the most gentle one\n",
        "* `nltk.stem.SnowballStemmer(language='english')` - improvement over porter\n",
        "* `nltk.stem.lancaster.LancasterStemmer(language='english')` - the fastest but very agressive\n",
        "\n",
        "We choose Snowball Stemmer.\n",
        "\n",
        "We also examined lemmatizing but it was unacceptably slow."
      ],
      "id": "bc83a267"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xDRl2_XPMhB"
      },
      "source": [
        "stemmer = nltk.stem.SnowballStemmer(language='english')"
      ],
      "id": "_xDRl2_XPMhB",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9b0ed83"
      },
      "source": [
        "def stem_tokens(tokens, stemmer):\n",
        "    return [stemmer.stem(token) for token in tokens]"
      ],
      "id": "f9b0ed83",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43d59031",
        "outputId": "e1584574-18c0-45ac-d459-aa8efb28e304"
      },
      "source": [
        "test_tokens = stem_tokens(test_tokens, stemmer)\n",
        "print(test_tokens)"
      ],
      "id": "43d59031",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['file', 'index', '.html', '.file', '.txt', 'file', '.c', 'file', '.ext-with-dash', 'hope', 'toktok-token', 'proper', 'token', 'new', 'line', 'new', 'sentenc', 'common', 'tag', 'c#', 'r', 'c++', 'c++11', 'c', 'not', 'frequent', 'word', 'number', 'word1', 'word32', 'word-2', 'function', 'main', 'str', 'f', '.there', 'url', 'number', '1', '2021', '3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6be7a8d"
      },
      "source": [
        "### Final preprocessing"
      ],
      "id": "c6be7a8d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4fcef92"
      },
      "source": [
        "def preprocess_text(text, tokenize=True, word_tokenizer=None, html=True, clean=True, abbr_dict = None, urls=True, extensions=True, \n",
        "                    punctuation=True, stopwords=True, stopword_list=None,\n",
        "                    numbers=True, stem=True, stemmer=None):\n",
        "    if html:\n",
        "        text = remove_html(text)\n",
        "\n",
        "    if abbr_dict is None:\n",
        "        abbr_dict = {}\n",
        "\n",
        "    if clean:\n",
        "        text = clean_text(text, abbr_dict)\n",
        "        \n",
        "    if tokenize:\n",
        "        if word_tokenizer is None:\n",
        "            nltk.tokenize.ToktokTokenizer()\n",
        "        tokens = tokenize_text(text, word_tokenizer)\n",
        "    else:\n",
        "        tokens = text\n",
        "        \n",
        "    if urls:\n",
        "        tokens = remove_urls(tokens)\n",
        "\n",
        "    if extensions:\n",
        "        tokens = extract_extensions(tokens)\n",
        "\n",
        "    if punctuation:\n",
        "        tokens = remove_punctuation(tokens)\n",
        "        \n",
        "    if stopword_list is None:\n",
        "        stopword_list = []\n",
        "    \n",
        "    if stopwords:\n",
        "        tokens = remove_stopwords(tokens, stopword_list)\n",
        "        \n",
        "    if numbers:\n",
        "        tokens = process_numbers(tokens)\n",
        "\n",
        "    if stem:\n",
        "        if stemmer is None:\n",
        "            stemmer = nltk.stem.SnowballStemmer(language='english')\n",
        "        tokens = stem_tokens(tokens, stemmer)\n",
        "        \n",
        "    return tokens"
      ],
      "id": "c4fcef92",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddf23d76"
      },
      "source": [
        "body_tokens = data['Body'].apply(lambda x : preprocess_text(x, word_tokenizer=word_tokenizer, stopword_list=my_stopwords, stemmer=stemmer))"
      ],
      "id": "ddf23d76",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2496438"
      },
      "source": [
        "title_tokens = data['Title'].apply(lambda x : preprocess_text(x, word_tokenizer=word_tokenizer, stopword_list=my_stopwords, stemmer=stemmer))"
      ],
      "id": "a2496438",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ead19cb"
      },
      "source": [
        "## Analyse all tokens"
      ],
      "id": "7ead19cb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b24c66f"
      },
      "source": [
        "all_tokens = []\n",
        "for tok in body_tokens:\n",
        "    for t in tok:\n",
        "        all_tokens.append(t)"
      ],
      "id": "5b24c66f",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "312bc2c6",
        "outputId": "c3e3eb07-8467-4852-8b1a-f1b2ae3c365b"
      },
      "source": [
        "len(all_tokens) "
      ],
      "id": "312bc2c6",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "722510"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb32db1b"
      },
      "source": [
        "t, c = np.unique(all_tokens, return_counts=True)\n",
        "unique_tokens = dict(zip(list(t), list(c)))"
      ],
      "id": "eb32db1b",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVEYlBX7cIxA",
        "outputId": "131a683e-e1f8-4448-9eae-9a23001b9df1"
      },
      "source": [
        "print(\"The number of unique tokens: \", len(unique_tokens))"
      ],
      "id": "cVEYlBX7cIxA",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique tokens:  63184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a074bcd",
        "outputId": "4b2b9106-85a8-446c-c71b-479dfa7f21b4"
      },
      "source": [
        "print(\"Average token count:\", np.average(list(unique_tokens.values())))"
      ],
      "id": "4a074bcd",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average token count: 11.435015193719929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41f49d03",
        "outputId": "f160ed41-0831-40b7-ba49-8c4af1949694"
      },
      "source": [
        "less_then = 3\n",
        "rare_tokens = [t for t, c in unique_tokens.items() if c < less_then]\n",
        "print(\"Tokens that appear less then\", less_then, \"times:\")\n",
        "print(\"====================================\")\n",
        "print(\"Size: \", len(rare_tokens), \"Sample: \", rare_tokens[:50])"
      ],
      "id": "41f49d03",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens that appear less then 3 times:\n",
            "====================================\n",
            "Size:  43950 Sample:  ['&\\\\mbox{', '&amp', '*', '*/', '+', '+$', '+dfsg-8~bpo60+1', ',0,0,0,0,0,0,0,0', ',0,0,10,28', ',0,1,0', ',0,1,0,0,0,0,0', ',0,1,1', ',0,2,0,1,0,0,0', ',0,20,0', ',0,282,210', ',0,320,480', ',0,5,0', ',0,95,34', ',0-1,1', ',1,2', ',1,2,2,1,0,0,0', ',10', ',10,0,0', ',100', ',11,12,13,14,15,7,8', ',15,0,0', ',15,30,45', ',15ms', ',18,17,22', ',2,1,1,2,1,1,0', ',2,2,2,2,0,0,0', ',2,4,6,8,10,12,14,16,18,20,22', ',20,0,0', ',200$', ',200,100,1', ',22', ',25ms', ',4', ',5,0,5', ',5,5', ',5,6,8', ',6', ',80,0,38', '-', '-11', '-1114111', '-128', '-17', '-255', '-3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0f9610d",
        "outputId": "848c9744-3616-4a76-dbd6-47522ef1ac50"
      },
      "source": [
        "more_then = 500\n",
        "very_frequent_tokens = [(t, c) for t, c in unique_tokens.items() if c > more_then]\n",
        "print(\"Tokens that appear more then\", more_then, \"times:\")\n",
        "print(\"======================================\")\n",
        "print(\"Size: \", len(very_frequent_tokens), \"Sample: \", very_frequent_tokens[:50])"
      ],
      "id": "d0f9610d",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens that appear more then 500 times:\n",
            "======================================\n",
            "Size:  241 Sample:  [('.0', 965), ('.java', 1343), ('.net', 666), ('1', 11725), ('124;', 2462), ('2', 5919), ('3', 3649), ('4', 3057), ('5', 2880), ('6', 1435), ('7', 1235), ('8', 1065), ('9', 955), ('abl', 642), ('about', 1050), ('access', 741), ('activ', 564), ('ad', 627), ('add', 1528), ('also', 1151), ('amp;', 635), ('android', 2541), ('anoth', 663), ('anyon', 727), ('app', 1219), ('applic', 1637), ('array', 1347), ('b', 828), ('base', 549), ('button', 975), ('c', 1202), ('call', 1598), ('case', 685), ('chang', 1327), ('check', 816), ('class', 2360), ('class=', 977), ('click', 850), ('client', 618), ('close', 511), ('code', 3553), ('column', 729), ('connect', 1061), ('contain', 751), ('content', 697), ('context', 563), ('control', 888), ('correct', 597), ('could', 985), ('creat', 2159)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e44ca9ce",
        "outputId": "318ac3be-cccb-49b8-fc6a-012c2fd5c259"
      },
      "source": [
        "normal_frequency_tokens = [t for t, c in unique_tokens.items() if c < more_then and c > less_then]\n",
        "print(\"Tokens that appear between\", less_then, \"and\", more_then, \"times:\")\n",
        "print(\"==========================================\")\n",
        "print(\"Size: \", len(normal_frequency_tokens), \"Sample: \", normal_frequency_tokens[:50])"
      ],
      "id": "e44ca9ce",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens that appear between 3 and 500 times:\n",
            "==========================================\n",
            "Size:  13994 Sample:  ['$', '**', '***', '*16', ',0', ',0,0', ',0,0,0', ',0,0,0,0,0,0,0', ',000', ',1', ',1,2,3', ',2', '-00-00', '-06', '-1', '-5', '-9', '.', '.-', '.0-', '.00', '.000', '.0000', '.00000', '.000000', '.0000000', '.00000000', '.000000000', '.0000000000', '.000006', '.0000090', '.0004882812', '.0009765625', '.001', '.0010000', '.001953125', '.0019531250', '.00390625', '.003906250', '.004', '.007', '.0078125', '.00781250', '.0079', '.009', '.009342', '.01', '.010', '.014', '.015']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esPMG3Tsw2th"
      },
      "source": [
        "### Years in text"
      ],
      "id": "esPMG3Tsw2th"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d38461b0"
      },
      "source": [
        "def count_occurances(s, tokens):\n",
        "    count = 0\n",
        "    for token in tokens:\n",
        "        if token == s:\n",
        "            count += 1\n",
        "    return count"
      ],
      "id": "d38461b0",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfEuQpYIxQnY",
        "outputId": "51d9b595-26f8-416b-86f7-cb21fbd46af5"
      },
      "source": [
        "print(\"Num of occurances of '2008':\", count_occurances(\"2008\", all_tokens))\n",
        "print(\"Num of occurances of '2010':\", count_occurances(\"2010\", all_tokens))"
      ],
      "id": "UfEuQpYIxQnY",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of occurances of '2008': 134\n",
            "Num of occurances of '2010': 131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68792b3a"
      },
      "source": [
        "## Compare results with original"
      ],
      "id": "68792b3a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cbdb8bc"
      },
      "source": [
        "index=8"
      ],
      "id": "6cbdb8bc",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "370ef2a9",
        "outputId": "fd388541-73ec-4164-e841-3bde254d2f8c"
      },
      "source": [
        "data[\"Body\"][index]"
      ],
      "id": "370ef2a9",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<p>Do you know of a .NET library for generating javascript code? </p>\\n\\n<p>I want to generate javascript code based on information in my .NET application. I would like to be able to create an AST-like datastructure (using C#) and have it turned into valid javascript. I need to be able to create functions, statements, expressions etc., so I need something more than a JSON serializer - but I guess you could think of this as a (<em>very</em>) generalized JSON serializer.</p>\\n\\n<p>Do such libraries exist and if so, could you recommend any?</p>\\n\\n<p>Thank you.</p>\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b6e4394",
        "outputId": "5e762de2-4028-443f-9d24-8431591ce9b8"
      },
      "source": [
        "print(body_tokens[index])"
      ],
      "id": "8b6e4394",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['know', '.net', 'librari', 'generat', 'javascript', 'code', 'want', 'generat', 'javascript', 'code', 'base', 'on', 'inform', '.net', 'applic', 'would', 'like', 'abl', 'creat', 'ast-lik', 'datastructur', 'use', 'c#', 'turn', 'valid', 'javascript', 'need', 'abl', 'creat', 'function', 'statement', 'express', 'etc.', 'need', 'someth', 'json', 'serial', 'guess', 'could', 'think', 'general', 'json', 'serial', 'librari', 'exist', 'could', 'recommend', 'thank']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bd977a0f",
        "outputId": "c03e83c9-7c1c-4afc-d64e-d3541168fcff"
      },
      "source": [
        "data[\"Title\"][index]"
      ],
      "id": "bd977a0f",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'.NET library for generating javascript?'"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14716d61",
        "outputId": "e1a42ee7-a1b4-4869-a090-28c6cc07ffc7"
      },
      "source": [
        "print(title_tokens[index])"
      ],
      "id": "14716d61",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.net', 'librari', 'generat', 'javascript']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a0e4a1a"
      },
      "source": [
        "## Save new data"
      ],
      "id": "5a0e4a1a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "338a6f3b"
      },
      "source": [
        "# Suppress SettingWithCopyWarning\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "\n",
        "data['Body'] = body_tokens\n",
        "data['Title'] = title_tokens\n",
        "\n",
        "pd.set_option('mode.chained_assignment', 'warn')"
      ],
      "id": "338a6f3b",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1584b205",
        "outputId": "ee6f8911-652f-467d-f5b1-754ea5aea2c1"
      },
      "source": [
        "data.head()"
      ],
      "id": "1584b205",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[how, check, upload, file, imag, without, mime...</td>\n",
              "      <td>[like, check, upload, file, imag, file, e, .g,...</td>\n",
              "      <td>[php]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[how, prevent, firefox, close, press, ctrl-w]</td>\n",
              "      <td>[favorit, editor, vim, regular, use, ctrl-w, e...</td>\n",
              "      <td>[firefox]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[r, error, invalid, type, list, variabl]</td>\n",
              "      <td>[import, matlab, file, construct, data, frame,...</td>\n",
              "      <td>[r]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[how, replac, special, charact, url]</td>\n",
              "      <td>[probabl, simpl, simpli, cannot, find, answer,...</td>\n",
              "      <td>[c#]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[how, modifi, whoi, contact, detail]</td>\n",
              "      <td>[function, modifi, mcontact, file_get_cont, ui...</td>\n",
              "      <td>[php, api]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...        Tags\n",
              "0   1  ...       [php]\n",
              "1   2  ...   [firefox]\n",
              "2   3  ...         [r]\n",
              "3   4  ...        [c#]\n",
              "4   5  ...  [php, api]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94f97df8"
      },
      "source": [
        "file = open(project_path + \"data/data_preprocessed.csv\", \"wb\")\n",
        "pickle.dump(data, file)\n",
        "file.close()"
      ],
      "id": "94f97df8",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKrCNJ_w9G9z"
      },
      "source": [
        "## Preprocess Tags (for Heuristic)"
      ],
      "id": "dKrCNJ_w9G9z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "208017ba"
      },
      "source": [
        "preprocessed_tags = data['Tags'].apply(lambda x : preprocess_text(x, tokenize=False, html=False, clean=False, urls=False,\n",
        "                                                                  extensions=False, punctuation=True,  stopwords=False, \n",
        "                                                                  numbers=False, stem=True, stemmer=stemmer))"
      ],
      "id": "208017ba",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB_EiaGriLRj",
        "outputId": "89c524b6-bdd4-4c48-e744-47a66c75e949"
      },
      "source": [
        "data['Tags'][40]"
      ],
      "id": "jB_EiaGriLRj",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iphone', 'xcode']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkh1t4hDiGJD",
        "outputId": "5dad4234-0cad-45b7-f7aa-7cddb2c2b734"
      },
      "source": [
        "preprocessed_tags[40]"
      ],
      "id": "Rkh1t4hDiGJD",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iphon', 'xcode']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12ccc125"
      },
      "source": [
        "file = open(project_path + \"data/tags_preprocessed.csv\", \"wb\")\n",
        "pickle.dump(preprocessed_tags, file)\n",
        "file.close()"
      ],
      "id": "12ccc125",
      "execution_count": 79,
      "outputs": []
    }
  ]
}